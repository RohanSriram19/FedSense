{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "02ea35dc",
   "metadata": {},
   "source": [
    "# FedSense Data Exploration\n",
    "\n",
    "This notebook explores synthetic wearable sensor data for federated anomaly detection.\n",
    "\n",
    "**Goals:**\n",
    "- Generate and examine synthetic time-series data (HR + accelerometer)\n",
    "- Analyze data distribution across federated clients\n",
    "- Visualize normal vs anomalous patterns\n",
    "- Demonstrate windowing and preprocessing steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b991984",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Required Libraries\n",
    "import sys\n",
    "import os\n",
    "sys.path.append('..')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# FedSense imports\n",
    "from fedsense.config import get_config\n",
    "from fedsense.datasets import generate_synthetic_data, create_federated_splits\n",
    "from fedsense.features import make_windows, get_dataset_stats\n",
    "\n",
    "# Set style\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(\"Libraries imported successfully!\")\n",
    "print(f\"NumPy version: {np.__version__}\")\n",
    "print(f\"Pandas version: {pd.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed0a8f91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Configuration\n",
    "config = get_config()\n",
    "\n",
    "print(\"FedSense Configuration:\")\n",
    "print(f\"  Window Length: {config.window_len} samples\")\n",
    "print(f\"  Stride: {config.stride} samples\")\n",
    "print(f\"  Number of Clients: {config.n_clients}\")\n",
    "print(f\"  Random Seed: {config.random_seed}\")\n",
    "print(f\"  Data Directory: {config.data_dir}\")\n",
    "\n",
    "# Set up random seed for reproducibility\n",
    "np.random.seed(config.random_seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bcc11f8",
   "metadata": {},
   "source": [
    "## 1. Generate Synthetic Data\n",
    "\n",
    "First, let's generate synthetic wearable sensor data that mimics real physiological signals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c20e8091",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate synthetic wearable data\n",
    "synthetic_df = generate_synthetic_data(\n",
    "    n_samples=10000,\n",
    "    fs=50.0,  # 50 Hz sampling rate\n",
    "    window_len=config.window_len,\n",
    "    anomaly_rate=0.1,  # 10% anomalies\n",
    "    random_seed=config.random_seed\n",
    ")\n",
    "\n",
    "print(f\"Generated dataset shape: {synthetic_df.shape}\")\n",
    "print(f\"Columns: {list(synthetic_df.columns)}\")\n",
    "print(f\"Anomaly rate: {synthetic_df['label'].mean():.3f}\")\n",
    "print(f\"Time range: {synthetic_df['timestamp'].min()} to {synthetic_df['timestamp'].max()}\")\n",
    "\n",
    "# Display first few rows\n",
    "synthetic_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddfeb627",
   "metadata": {},
   "source": [
    "## 2. Visualize Raw Time-Series Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4d21bd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot a subset of the time series data\n",
    "plot_duration = 300  # Plot 300 seconds (5 minutes)\n",
    "plot_samples = int(plot_duration * 50)  # 50 Hz\n",
    "plot_data = synthetic_df.head(plot_samples).copy()\n",
    "\n",
    "fig, axes = plt.subplots(4, 1, figsize=(15, 12))\n",
    "\n",
    "# Time vector for x-axis\n",
    "time_seconds = np.arange(len(plot_data)) / 50.0\n",
    "\n",
    "# Heart Rate\n",
    "axes[0].plot(time_seconds, plot_data['hr'], 'b-', linewidth=0.8)\n",
    "anomaly_mask = plot_data['label'] == 1\n",
    "if anomaly_mask.any():\n",
    "    axes[0].scatter(time_seconds[anomaly_mask], plot_data['hr'][anomaly_mask], \n",
    "                   c='red', s=10, alpha=0.7, label='Anomaly')\n",
    "axes[0].set_ylabel('Heart Rate (BPM)')\n",
    "axes[0].set_title('Synthetic Wearable Sensor Data')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Accelerometer X\n",
    "axes[1].plot(time_seconds, plot_data['accel_x'], 'g-', linewidth=0.8)\n",
    "if anomaly_mask.any():\n",
    "    axes[1].scatter(time_seconds[anomaly_mask], plot_data['accel_x'][anomaly_mask], \n",
    "                   c='red', s=10, alpha=0.7)\n",
    "axes[1].set_ylabel('Accel X (m/s²)')\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "# Accelerometer Y\n",
    "axes[2].plot(time_seconds, plot_data['accel_y'], 'orange', linewidth=0.8)\n",
    "if anomaly_mask.any():\n",
    "    axes[2].scatter(time_seconds[anomaly_mask], plot_data['accel_y'][anomaly_mask], \n",
    "                   c='red', s=10, alpha=0.7)\n",
    "axes[2].set_ylabel('Accel Y (m/s²)')\n",
    "axes[2].grid(True, alpha=0.3)\n",
    "\n",
    "# Accelerometer Z\n",
    "axes[3].plot(time_seconds, plot_data['accel_z'], 'purple', linewidth=0.8)\n",
    "if anomaly_mask.any():\n",
    "    axes[3].scatter(time_seconds[anomaly_mask], plot_data['accel_z'][anomaly_mask], \n",
    "                   c='red', s=10, alpha=0.7)\n",
    "axes[3].set_ylabel('Accel Z (m/s²)')\n",
    "axes[3].set_xlabel('Time (seconds)')\n",
    "axes[3].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Plotted {plot_duration} seconds of data ({plot_samples} samples)\")\n",
    "print(f\"Anomalies in this segment: {anomaly_mask.sum()} ({anomaly_mask.mean():.2%})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5e0b210",
   "metadata": {},
   "source": [
    "## 3. Windowing and Preprocessing\n",
    "\n",
    "Demonstrate how raw time-series data is converted into windows for machine learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4088566f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create windows from the synthetic data\n",
    "X, y = make_windows(\n",
    "    synthetic_df, \n",
    "    window_len=config.window_len, \n",
    "    stride=config.stride,\n",
    "    target_col='label'\n",
    ")\n",
    "\n",
    "print(f\"Window shape: {X.shape}\")\n",
    "print(f\"Labels shape: {y.shape}\")\n",
    "print(f\"Feature interpretation: (n_windows={X.shape[0]}, window_len={X.shape[1]}, n_features={X.shape[2]})\")\n",
    "print(f\"Features are: [HR, Accel_X, Accel_Y, Accel_Z]\")\n",
    "print(f\"Window anomaly rate: {y.mean():.3f}\")\n",
    "\n",
    "# Visualize a few example windows\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "axes = axes.flatten()\n",
    "\n",
    "# Show 2 normal and 2 anomalous windows\n",
    "normal_indices = np.where(y == 0)[0][:2]\n",
    "anomaly_indices = np.where(y == 1)[0][:2]\n",
    "\n",
    "window_indices = list(normal_indices) + list(anomaly_indices)\n",
    "titles = ['Normal Window 1', 'Normal Window 2', 'Anomaly Window 1', 'Anomaly Window 2']\n",
    "colors = ['blue', 'green', 'red', 'orange']\n",
    "\n",
    "for i, (window_idx, title, color) in enumerate(zip(window_indices, titles, colors)):\n",
    "    window_data = X[window_idx]  # Shape: (window_len, n_features)\n",
    "    time_steps = np.arange(window_data.shape[0]) / 50.0  # Convert to seconds\n",
    "    \n",
    "    ax = axes[i]\n",
    "    \n",
    "    # Plot heart rate\n",
    "    ax2 = ax.twinx()\n",
    "    ax.plot(time_steps, window_data[:, 0], 'r-', linewidth=2, alpha=0.8, label='HR')\n",
    "    \n",
    "    # Plot acceleration magnitude\n",
    "    accel_mag = np.sqrt(window_data[:, 1]**2 + window_data[:, 2]**2 + window_data[:, 3]**2)\n",
    "    ax2.plot(time_steps, accel_mag, color=color, linewidth=2, alpha=0.7, label='Accel Mag')\n",
    "    \n",
    "    ax.set_xlabel('Time (s)')\n",
    "    ax.set_ylabel('Heart Rate (BPM)', color='r')\n",
    "    ax2.set_ylabel('Accel Magnitude (m/s²)', color=color)\n",
    "    ax.set_title(f'{title} (Label: {y[window_idx]})')\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Add legends\n",
    "    lines1, labels1 = ax.get_legend_handles_labels()\n",
    "    lines2, labels2 = ax2.get_legend_handles_labels()\n",
    "    ax.legend(lines1 + lines2, labels1 + labels2, loc='upper right')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdbe4343",
   "metadata": {},
   "source": [
    "## 4. Federated Data Distribution\n",
    "\n",
    "Analyze how data is distributed across federated clients in a non-IID manner."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d43cb89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create federated data splits\n",
    "data_splits = create_federated_splits(\n",
    "    df=synthetic_df,\n",
    "    n_clients=config.n_clients,\n",
    "    alpha=0.1,  # Low alpha = more non-IID\n",
    "    random_seed=config.random_seed\n",
    ")\n",
    "\n",
    "# Analyze distribution across clients\n",
    "client_stats = []\n",
    "for client_id, client_data in data_splits.items():\n",
    "    stats = {\n",
    "        'client_id': client_id,\n",
    "        'n_samples': len(client_data),\n",
    "        'anomaly_rate': client_data['label'].mean(),\n",
    "        'avg_hr': client_data['hr'].mean(),\n",
    "        'std_hr': client_data['hr'].std(),\n",
    "        'avg_accel_x': client_data['accel_x'].mean(),\n",
    "        'avg_accel_y': client_data['accel_y'].mean(),\n",
    "        'avg_accel_z': client_data['accel_z'].mean(),\n",
    "    }\n",
    "    client_stats.append(stats)\n",
    "\n",
    "client_stats_df = pd.DataFrame(client_stats)\n",
    "print(\"Federated Client Statistics:\")\n",
    "print(client_stats_df.round(3))\n",
    "\n",
    "# Visualize client distributions\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "\n",
    "# Anomaly rate per client\n",
    "axes[0, 0].bar(client_stats_df['client_id'], client_stats_df['anomaly_rate'])\n",
    "axes[0, 0].set_xlabel('Client ID')\n",
    "axes[0, 0].set_ylabel('Anomaly Rate')\n",
    "axes[0, 0].set_title('Anomaly Rate Distribution Across Clients')\n",
    "axes[0, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# Sample count per client\n",
    "axes[0, 1].bar(client_stats_df['client_id'], client_stats_df['n_samples'])\n",
    "axes[0, 1].set_xlabel('Client ID')\n",
    "axes[0, 1].set_ylabel('Number of Samples')\n",
    "axes[0, 1].set_title('Data Volume per Client')\n",
    "axes[0, 1].grid(True, alpha=0.3)\n",
    "\n",
    "# Average heart rate per client\n",
    "axes[1, 0].bar(client_stats_df['client_id'], client_stats_df['avg_hr'])\n",
    "axes[1, 0].set_xlabel('Client ID')\n",
    "axes[1, 0].set_ylabel('Average HR (BPM)')\n",
    "axes[1, 0].set_title('Average Heart Rate per Client')\n",
    "axes[1, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# Heart rate variability per client\n",
    "axes[1, 1].bar(client_stats_df['client_id'], client_stats_df['std_hr'])\n",
    "axes[1, 1].set_xlabel('Client ID')\n",
    "axes[1, 1].set_ylabel('HR Standard Deviation')\n",
    "axes[1, 1].set_title('Heart Rate Variability per Client')\n",
    "axes[1, 1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nNon-IID Statistics:\")\n",
    "print(f\"Anomaly rate range: {client_stats_df['anomaly_rate'].min():.3f} - {client_stats_df['anomaly_rate'].max():.3f}\")\n",
    "print(f\"Sample count range: {client_stats_df['n_samples'].min()} - {client_stats_df['n_samples'].max()}\")\n",
    "print(f\"HR mean range: {client_stats_df['avg_hr'].min():.1f} - {client_stats_df['avg_hr'].max():.1f} BPM\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09e0c5ba",
   "metadata": {},
   "source": [
    "## 5. Feature Correlation and Distribution Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62b38cba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature correlation analysis\n",
    "feature_cols = ['hr', 'accel_x', 'accel_y', 'accel_z', 'label']\n",
    "correlation_matrix = synthetic_df[feature_cols].corr()\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 6))\n",
    "\n",
    "# Correlation heatmap\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='RdBu_r', center=0,\n",
    "            square=True, ax=axes[0])\n",
    "axes[0].set_title('Feature Correlation Matrix')\n",
    "\n",
    "# Feature distributions by class\n",
    "normal_data = synthetic_df[synthetic_df['label'] == 0]\n",
    "anomaly_data = synthetic_df[synthetic_df['label'] == 1]\n",
    "\n",
    "# Heart rate distributions\n",
    "axes[1].hist(normal_data['hr'], bins=50, alpha=0.7, label='Normal', color='blue')\n",
    "axes[1].hist(anomaly_data['hr'], bins=50, alpha=0.7, label='Anomaly', color='red')\n",
    "axes[1].set_xlabel('Heart Rate (BPM)')\n",
    "axes[1].set_ylabel('Frequency')\n",
    "axes[1].set_title('Heart Rate Distribution by Class')\n",
    "axes[1].legend()\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Summary statistics by class\n",
    "print(\"Summary Statistics by Class:\")\n",
    "print(\"\\nNormal samples:\")\n",
    "print(normal_data[['hr', 'accel_x', 'accel_y', 'accel_z']].describe().round(2))\n",
    "\n",
    "print(\"\\nAnomalous samples:\")\n",
    "print(anomaly_data[['hr', 'accel_x', 'accel_y', 'accel_z']].describe().round(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc50507c",
   "metadata": {},
   "source": [
    "## 6. Summary and Next Steps\n",
    "\n",
    "### Key Findings\n",
    "\n",
    "1. **Data Quality**: Synthetic data successfully mimics physiological patterns\n",
    "2. **Anomaly Patterns**: Clear differences in HR and acceleration between normal/anomalous periods\n",
    "3. **Non-IID Distribution**: Significant variation in anomaly rates and signal characteristics across clients\n",
    "4. **Windowing**: 250-sample windows (5 seconds) effectively capture temporal patterns\n",
    "\n",
    "### Data Characteristics\n",
    "\n",
    "- **Sampling Rate**: 50 Hz (realistic for wearable devices)\n",
    "- **Window Length**: 5 seconds (250 samples) \n",
    "- **Features**: Heart rate + 3-axis accelerometer\n",
    "- **Class Balance**: ~10% anomalies (realistic for health monitoring)\n",
    "- **Federated Splits**: 8 clients with varying data distributions\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "1. **Feature Engineering**: Explore FFT features, rolling statistics\n",
    "2. **Model Training**: Train JAX/Flax CNN on windowed data\n",
    "3. **Federated Learning**: Compare centralized vs federated performance\n",
    "4. **Differential Privacy**: Evaluate privacy-accuracy tradeoffs\n",
    "5. **Model Deployment**: Export to ONNX and serve via Triton\n",
    "\n",
    "### Model Development Pipeline\n",
    "\n",
    "```bash\n",
    "# Generate federated data\n",
    "make data\n",
    "\n",
    "# Train centralized baseline\n",
    "make train_local\n",
    "\n",
    "# Run federated learning  \n",
    "make fl_server    # Terminal 1\n",
    "make fl_client    # Terminal 2-N (multiple clients)\n",
    "\n",
    "# Export and deploy\n",
    "make export\n",
    "make triton_up\n",
    "make api_up\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
